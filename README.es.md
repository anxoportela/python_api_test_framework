## ğŸ **Framework de Pruebas de API en Python** ğŸš€

[![EspaÃ±ol](https://img.shields.io/badge/Language-Spanish-red)](README.es.md)
[![English](https://img.shields.io/badge/Language-English-blue)](README.md)

Bienvenido! Escoge tu lenguaje preferido.

### ğŸŒŸ **DescripciÃ³n del Proyecto**

Â¡Bienvenido al **Framework de Pruebas de API en Python**! Esta es una soluciÃ³n todo en uno para automatizar las pruebas de API, gestionar datos de prueba y generar informes interactivos. Construido con Python y varias bibliotecas modernas, este framework te permite:

- **Probar** APIs RESTful.
- **Gestionar** los datos de prueba desde archivos Excel.
- **Almacenar** los resultados en una base de datos (SQLite).
- **Visualizar** los resultados de las pruebas con un panel de control basado en dash.

---

### âš™ï¸ **CaracterÃ­sticas**

âœ¨ **CaracterÃ­sticas clave**:

- ğŸ§‘â€ğŸ’» **Cliente de API**: EnvÃ­a solicitudes HTTP (GET, POST, PUT, DELETE) para probar las APIs.
- ğŸ“Š **Lector y Escritor de Excel**: Lee los datos de prueba desde archivos `.xlsx` y escribe los resultados de vuelta en Excel.
- ğŸ—ƒï¸ **Gestor de Base de Datos**: Almacena los resultados de las pruebas en una base de datos SQLite.
- ğŸ“ˆ **Panel de Informes de Pruebas**: Muestra los resultados en una aplicaciÃ³n web basada en Dash.
- ğŸ“… **Informes Complejos**:
  - **Resumen de EjecuciÃ³n**: Pruebas Pasadas, Falladas y Saltadas.
  - **DistribuciÃ³n de Estados**: Visualiza la distribuciÃ³n de los estados de las pruebas.
  - **Histogramas de DuraciÃ³n**: Muestra la distribuciÃ³n de las duraciones de las pruebas.
  - **Tabla de Resultados**: Proporciona un registro detallado de los resultados de las pruebas.

---

### ğŸš€ **InstalaciÃ³n**

#### **1. Instalar Dependencias**

El framework requiere Python 3.12+ y varias dependencias. Para comenzar, clona el repositorio e instala los paquetes necesarios desde el archivo `requirements.txt`.

```bash
git clone https://github.com/anxoportela/python_api_test_framework.git
cd python-api-test-framework
```

#### **2. Configurar un Entorno Virtual (opcional, pero recomendado)**

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows usa venv\Scripts\activate
```

#### **3. Instalar las Dependencias Requeridas**

```bash
pip install -r requirements.txt
```

---

### ğŸ§ª **Ejecutar Pruebas**

Antes de lanzar el panel de Dash, es importante ejecutar las pruebas para generar los datos que se visualizarÃ¡n.

Para ejecutar las pruebas del framework, navega hasta el directorio raÃ­z y ejecuta lo siguiente:

```bash
pytest -s
```

Esto ejecutarÃ¡ las pruebas y proporcionarÃ¡ retroalimentaciÃ³n sobre el Ã©xito de los casos de prueba.

---

### ğŸš€ **Lanzar el Panel de Control de Dash** ğŸ’»

Una vez que las pruebas se han ejecutado y los resultados se han generado, puedes lanzar el panel de informes basado en Dash. Este mostrarÃ¡ los resultados de tus pruebas en una interfaz web interactiva.

```bash
python web/app.py
```

Abre tu navegador y accede a `http://127.0.0.1:8050/` para ver el panel.

---

### ğŸ“Š **Formato de los Datos de Prueba** (Excel)

El framework lee los datos de prueba desde un archivo Excel (`test_data.xlsx`) con las siguientes columnas en orden:

| Nombre de Columna      | DescripciÃ³n                                                         |
|------------------------|---------------------------------------------------------------------|
| **TestId**             | Identificador Ãºnico del caso de prueba.                             |
| **TestCase**           | Nombre o descripciÃ³n del caso de prueba.                            |
| **Run**                | Indica si la prueba debe ejecutarse (`Y`/`N`).                      |
| **Method**             | MÃ©todo HTTP a utilizar (GET, POST, PUT, DELETE).                    |
| **URL**                | La URL base de la API que se estÃ¡ probando.                         |
| **Endpoint**           | El endpoint especÃ­fico a probar, relativo a la URL base.            |
| **Authorization**      | Cadena de autorizaciÃ³n requerida (ej., `Bearer`, `Basic` o `None`). |
| **User**               | Nombre de usuario (si es necesario para la autenticaciÃ³n).          |
| **Password**           | ContraseÃ±a (si es necesario para la autenticaciÃ³n).                 |
| **Headers**            | Cabeceras HTTP en formato JSON (opcional).                          |
| **Body**               | Cuerpo de la solicitud en formato JSON (para peticiones POST/PUT).  |
| **ExpectedStatusCode** | El cÃ³digo de estado HTTP esperado (ej., `200`, `404`).              |
| **ExpectedResponse**   | El cuerpo de la respuesta esperado (opcional, puede estar vacÃ­o).   |
| **Status**             | El resultado de la prueba (`Passed`, `Failed` o `Skipped`).         |
| **Error**              | Cualquier mensaje de error encontrado durante la prueba (opcional). |

---

#### ğŸ§‘â€ğŸ’» **CÃ³mo se Usan los Datos de Prueba**

- **TestCase**: La descripciÃ³n del caso de prueba se registra para mayor claridad.
- **Run**: Esta columna determina si el caso de prueba debe ejecutarse. Si `Run` estÃ¡ establecido en `N`, la prueba se omite.
- **Method**: Define el mÃ©todo de solicitud HTTP a utilizar (ej., `GET`, `POST`).
- **URL + Endpoint**: Combinados, estos forman la URL completa para la solicitud. La URL base y el `Endpoint` especÃ­fico se unirÃ¡n programÃ¡ticamente.
- **Authorization, User, Password**: Se utilizan para solicitudes autenticadas (ej., con tokens Bearer o AutenticaciÃ³n BÃ¡sica).
- **Headers & Body**: Si es necesario, las cabeceras HTTP y los cuerpos de las solicitudes se envÃ­an como parte de la llamada a la API.
- **ExpectedStatusCode & ExpectedResponse**: La respuesta real se compara con estos valores para determinar si la prueba pasa o falla.
- **Status**: DespuÃ©s de cada ejecuciÃ³n de prueba, esta columna se actualiza con el resultado de la prueba.
- **Error**: Si la prueba falla o ocurre un error, el mensaje de error se registra aquÃ­ para un anÃ¡lisis posterior.

---

### ğŸ“ **Estructura del Proyecto**

```bash
python_api_test_framework/
â”‚
â”œâ”€â”€ core/                    # LÃ³gica para solicitudes API y gestiÃ³n de datos de prueba
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del paquete principal
â”‚   â”œâ”€â”€ api_client.py        # Maneja las solicitudes de API
â”‚   â”œâ”€â”€ excel_reader.py      # Lee los datos de prueba desde archivos Excel
â”‚   â”œâ”€â”€ excel_writer.py      # Escribe los resultados de las pruebas en archivos Excel
â”‚   â”œâ”€â”€ test_data_model.py   # Define el modelo de datos de prueba
â”‚   â”œâ”€â”€ db_manager.py        # Maneja las interacciones con la base de datos
â”‚
â”œâ”€â”€ data/                    # Almacena los datos de prueba
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del paquete de datos
â”‚   â”œâ”€â”€ test_data.xlsx       # Datos de prueba de ejemplo
â”‚
â”œâ”€â”€ reports/                 # Almacena los informes generados y los resultados de las pruebas
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del paquete de informes
â”‚   â”œâ”€â”€ results.db           # Base de datos SQLite para los resultados de las pruebas
â”‚
â”œâ”€â”€ tests/                   # Pruebas unitarias y funcionales para el framework
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del paquete de pruebas
â”‚   â””â”€â”€ test_api.py          # Lanzador de pruebas para el framework
â”‚
â”œâ”€â”€ web/                     # AplicaciÃ³n web para los informes de pruebas
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del paquete web
â”‚   â”œâ”€â”€ app.py               # AplicaciÃ³n Dash para visualizar los informes de pruebas
â”‚
â”œâ”€â”€ config.py                # ConfiguraciÃ³n global del proyecto
â”œâ”€â”€ requirements.txt         # Lista de dependencias necesarias
â”œâ”€â”€ LICENSE                  # Licencia del proyecto
â”œâ”€â”€ README.es.md             # EstÃ¡s aquÃ­ ahora mismo ğŸ˜…
â”œâ”€â”€ README.md                # README en InglÃ©s
```

---

### ğŸ› ï¸ **CÃ³mo Funciona**

#### ğŸ“¡ **Cliente de API**

El archivo `api_client.py` maneja las solicitudes y respuestas de la API. Soporta varios mÃ©todos HTTP (GET, POST, PUT, DELETE) y almacena los resultados, incluidos los cÃ³digos de estado y los tiempos de respuesta.

#### ğŸ“‚ **GestiÃ³n de Datos de Prueba**

Los datos de prueba se leen desde un archivo Excel (`test_data.xlsx`) utilizando el script `excel_reader.py`. Estos datos incluyen tÃ­picamente los endpoints de la API, los mÃ©todos de solicitud y los resultados esperados. DespuÃ©s de ejecutar las pruebas, los resultados se escriben de nuevo en una nueva hoja del Excel utilizando `excel_writer.py`.

#### ğŸ—„ï¸ **GestiÃ³n de Base de Datos**

Los resultados de las pruebas se guardan en una base de datos SQLite (`results.db`). El archivo `db_manager.py` se encarga de insertar y recuperar los resultados de las pruebas.

#### ğŸ“Š **Panel de Informes**

El archivo `web/app.py` sirve como punto de entrada para el panel web basado en Dash. Este panel proporciona una vista completa de los resultados de las pruebas, incluyendo:

- **EstadÃ­sticas de Pruebas**: Resumen de las pruebas que pasaron, fallaron y fueron omitidas.
- **GrÃ¡ficos**:
  - **DistribuciÃ³n de Estados**: Muestra un grÃ¡fico de barras de los estados de las pruebas (Aprobadas, Fallidas, Omitidas).
  - **DistribuciÃ³n de Duraciones**: Visualiza la distribuciÃ³n de las duraciones de las pruebas.
  - **Tabla de Resultados**: Una tabla detallada de los resultados individuales de las pruebas, que incluye el estado, la duraciÃ³n y registros adicionales.

---

### ğŸ“ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Si deseas contribuir a este proyecto, por favor sigue estos pasos:

1. Haz un fork del proyecto.
2. Crea una nueva rama para tu feature o bugfix (`git checkout -b feature/nueva-feature`).
3. Realiza tus cambios y haz commit (`git commit -am 'Agrega nueva funcionalidad'`).
4. Sube tus cambios a tu fork (`git push origin feature/nueva-feature`).
5. Crea un pull request.

---

### ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la **Licencia MIT**. Para mÃ¡s detalles, consulta el archivo [LICENSE](LICENSE).

---

### ğŸ“§ **Contacto**

Para cualquier problema, pregunta o sugerencia, no dudes en contactar con los mantenedores del proyecto:

**Correo electrÃ³nico**: [hello@anxoportela.dev](mailto:hello@anxoportela.dev)

---

#### ğŸ‰ **Â¡Disfruta utilizando el Framework de Pruebas de API en Python!** ğŸ‰
